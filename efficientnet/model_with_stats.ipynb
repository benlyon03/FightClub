{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install opencv-python\n",
    "%pip install tqdm\n",
    "%pip install tensorflow\n",
    "%pip install imageio\n",
    "%pip install tensorflow_docs\n",
    "%pip install scikit-learn\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pathlib\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import imageio\n",
    "from IPython import display\n",
    "from urllib import request\n",
    "from tensorflow_docs.vis import embed\n",
    "from tensorflow.keras.metrics import Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_paths = {}\n",
    "subset_paths['train'] = Path('../Data/train')\n",
    "subset_paths['test'] = Path('../Data/test')\n",
    "subset_paths['val'] = Path('../Data/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_frames(frame, output_size):\n",
    "    \"\"\"\n",
    "      Pad and resize an image from a video.\n",
    "\n",
    "      Args:\n",
    "        frame: Image that needs to resized and padded.\n",
    "        output_size: Pixel size of the output frame image.\n",
    "\n",
    "      Return:\n",
    "        Formatted frame with padding of specified output size.\n",
    "    \"\"\"\n",
    "    frame = tf.image.convert_image_dtype(frame, tf.float32)\n",
    "    frame = tf.image.resize_with_pad(frame, *output_size)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def frames_from_video_file(video_path, n_frames, output_size=(224, 224), frame_step=15):\n",
    "    \"\"\"\n",
    "      Creates frames from each video file present for each category.\n",
    "\n",
    "      Args:\n",
    "        video_path: File path to the video.\n",
    "        n_frames: Number of frames to be created per video file.\n",
    "        output_size: Pixel size of the output frame image.\n",
    "\n",
    "      Return:\n",
    "        An NumPy array of frames in the shape of (n_frames, height, width, channels).\n",
    "    \"\"\"\n",
    "    # Read each video frame by frame\n",
    "    result = []\n",
    "    src = cv2.VideoCapture(str(video_path))\n",
    "\n",
    "    video_length = src.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "    need_length = 1 + (n_frames - 1) * frame_step\n",
    "\n",
    "    if need_length > video_length:\n",
    "        start = 0\n",
    "    else:\n",
    "        max_start = video_length - need_length\n",
    "        start = random.randint(0, max_start + 1)\n",
    "\n",
    "    src.set(cv2.CAP_PROP_POS_FRAMES, start)\n",
    "    # ret is a boolean indicating whether read was successful, frame is the image itself\n",
    "    ret, frame = src.read()\n",
    "    result.append(format_frames(frame, output_size))\n",
    "\n",
    "    for _ in range(n_frames - 1):\n",
    "        for _ in range(frame_step):\n",
    "            ret, frame = src.read()\n",
    "        if ret:\n",
    "            frame = format_frames(frame, output_size)\n",
    "            result.append(frame)\n",
    "        else:\n",
    "            result.append(np.zeros_like(result[0]))\n",
    "    src.release()\n",
    "    result = np.array(result)[..., [2, 1, 0]]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FrameGenerator:\n",
    "    def __init__(self, path, n_frames, training=False):\n",
    "        \"\"\" Returns a set of frames with their associated label.\n",
    "\n",
    "          Args:\n",
    "            path: Video file paths.\n",
    "            n_frames: Number of frames.\n",
    "            training: Boolean to determine if training dataset is being created.\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "        self.n_frames = n_frames\n",
    "        self.training = training\n",
    "        self.class_names = sorted(\n",
    "            set(p.name for p in self.path.iterdir() if p.is_dir()))\n",
    "        self.class_ids_for_name = dict((name, idx)\n",
    "                                       for idx, name in enumerate(self.class_names))\n",
    "\n",
    "    def get_files_and_class_names(self):\n",
    "        video_paths = list(self.path.glob('*/*.mp4'))\n",
    "        classes = [p.parent.name for p in video_paths]\n",
    "        return video_paths, classes\n",
    "\n",
    "    def __call__(self):\n",
    "        video_paths, classes = self.get_files_and_class_names()\n",
    "        pairs = list(zip(video_paths, classes))\n",
    "\n",
    "        if self.training:\n",
    "            random.shuffle(pairs)\n",
    "\n",
    "        for path, name in pairs:\n",
    "            video_frames = frames_from_video_file(path, self.n_frames)\n",
    "            label = self.class_ids_for_name[name]  # Encode labels\n",
    "            yield video_frames, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_signature = (tf.TensorSpec(shape=(None, None, None, 3), dtype=tf.float32),\n",
    "                    tf.TensorSpec(shape=(), dtype=tf.int16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames = 6\n",
    "\n",
    "train_ds = tf.data.Dataset.from_generator(FrameGenerator(\n",
    "    subset_paths['train'], num_frames, training=True),                                        output_signature=output_signature)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_generator(FrameGenerator(subset_paths['val'], num_frames),\n",
    "                                        output_signature=output_signature)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_generator(FrameGenerator(subset_paths['test'], num_frames),\n",
    "                                         output_signature=output_signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_frames, train_labels = next(iter(train_ds))\n",
    "val_frames, val_labels = next(iter(val_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_frames[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59095156"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_frames[num_frames-1][100][100][2].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of validation set of frames: (6, 224, 224, 3)\n",
      "Shape of validation labels: ()\n"
     ]
    }
   ],
   "source": [
    "# the _frames is a 4D array to descibe the pixels in a \"video\" (not actually a video but rather a gorup of frames to represent a video) \n",
    "# val_frames[# of frame in the video burst][height of pixel][width of pixel][R:G:B value]\n",
    "# ex. val_frames[2][0][0][2] will give the Blue value for the second frame in a video in the top left corner (since height = width = 0) and we will see the blue value (3rd in RGB)\n",
    "print(f'shape of val_frames is ({num_frames}=number of frames 224=height in pixels 224=width in pixels 3=RBG value of the pixel )')\n",
    "\n",
    "print(f'Shape of validation set of frames: {val_frames.shape}')\n",
    "print(f'Shape of validation labels: {val_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training set of frames: (6, 224, 224, 3)\n",
      "Shape of training labels: ()\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of training set of frames: {train_frames.shape}')\n",
    "print(f'Shape of training labels: {train_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, None, None, 3), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.int16, name=None))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fg = FrameGenerator(\n",
    "    subset_paths['train'], 6, training=True)\n",
    "output_signature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "train_ds = train_ds.batch(batch_size)\n",
    "val_ds = val_ds.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = tf.keras.applications.EfficientNetB0(include_top=False)\n",
    "net.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Rescaling(scale=255),\n",
    "    tf.keras.layers.TimeDistributed(net),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.GlobalAveragePooling3D()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                  from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_BatchDataset' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tassc\\Desktop\\FightClub\\efficientnet\\model_with_stats.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/tassc/Desktop/FightClub/efficientnet/model_with_stats.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_ds\u001b[39m.\u001b[39;49mshape\n",
      "\u001b[1;31mAttributeError\u001b[0m: '_BatchDataset' object has no attribute 'shape'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "210/210 [==============================] - 326s 1s/step - loss: 0.4279 - accuracy: 0.8651 - val_loss: 0.2010 - val_accuracy: 0.9083\n",
      "Epoch 2/2\n",
      " 85/210 [===========>..................] - ETA: 1:50 - loss: 0.1877 - accuracy: 0.9451"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tassc\\Desktop\\FightClub\\efficientnet\\model_with_stats.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/tassc/Desktop/FightClub/efficientnet/model_with_stats.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_ds,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tassc/Desktop/FightClub/efficientnet/model_with_stats.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m           epochs\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tassc/Desktop/FightClub/efficientnet/model_with_stats.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m           validation_data\u001b[39m=\u001b[39;49mval_ds,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tassc/Desktop/FightClub/efficientnet/model_with_stats.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m           callbacks\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mEarlyStopping(patience\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, monitor\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mval_loss\u001b[39;49m\u001b[39m'\u001b[39;49m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1776\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1777\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1780\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1781\u001b[0m ):\n\u001b[0;32m   1782\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1783\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1785\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    864\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    865\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    866\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    868\u001b[0m       args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[0;32m    869\u001b[0m   )\n\u001b[0;32m    870\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    872\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1261\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1262\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1263\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mflat_call(args)\n\u001b[0;32m   1265\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1266\u001b[0m     args,\n\u001b[0;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1268\u001b[0m     executing_eagerly)\n\u001b[0;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_call\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    216\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    218\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    251\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    253\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    254\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    255\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    256\u001b[0m     )\n\u001b[0;32m    257\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    259\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m    260\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[0;32m    261\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[0;32m    262\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1478\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1479\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1480\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1481\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1482\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1483\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1484\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1485\u001b[0m   )\n\u001b[0;32m   1486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1487\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1488\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1489\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1493\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1494\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_ds,\n",
    "          epochs=2,\n",
    "          validation_data=val_ds,\n",
    "          callbacks=tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = tf.data.Dataset.from_generator(FrameGenerator(subset_paths['test'], 6),                                       output_signature=output_signature)\n",
    "test_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.batch(2)\n",
    "test_frames, test_labels = next(iter(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 67s 676ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred  = model.predict(test_ds, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming test_ds is a TensorFlow dataset and y_pred_bool is a NumPy array\n",
    "y_true_list = []\n",
    "for data, labels in test_ds:\n",
    "    y_true_list.extend(labels.numpy())\n",
    "\n",
    "y_true = np.array(y_true_list)\n",
    "y_pred_bool = np.array(y_pred_bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_bool = np.where(y_pred_bool == 1, 'violence', 'nonviolence')\n",
    "# y_true = np.where(y_true == 1, 'violence', 'nonviolence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of FixedLocator locations (10), usually from a call to set_ticks, does not match the number of labels (2).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tassc\\Desktop\\FightClub\\efficientnet\\model_with_stats.ipynb Cell 23\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tassc/Desktop/FightClub/efficientnet/model_with_stats.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m cm \u001b[39m=\u001b[39m confusion_matrix(y_true, y_pred_bool)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tassc/Desktop/FightClub/efficientnet/model_with_stats.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m ConfusionMatrixDisplay(confusion_matrix\u001b[39m=\u001b[39;49mcm, display_labels\u001b[39m=\u001b[39;49m[\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tassc/Desktop/FightClub/efficientnet/model_with_stats.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mNonViolence\u001b[39;49m\u001b[39m'\u001b[39;49m , \u001b[39m'\u001b[39;49m\u001b[39mViolence\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/tassc/Desktop/FightClub/efficientnet/model_with_stats.ipynb#X31sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m ])\u001b[39m.\u001b[39;49mplot()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_plot\\confusion_matrix.py:181\u001b[0m, in \u001b[0;36mConfusionMatrixDisplay.plot\u001b[1;34m(self, include_values, cmap, xticks_rotation, values_format, ax, colorbar, im_kw, text_kw)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[39mif\u001b[39;00m colorbar:\n\u001b[0;32m    180\u001b[0m     fig\u001b[39m.\u001b[39mcolorbar(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mim_, ax\u001b[39m=\u001b[39max)\n\u001b[1;32m--> 181\u001b[0m ax\u001b[39m.\u001b[39;49mset(\n\u001b[0;32m    182\u001b[0m     xticks\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49marange(n_classes),\n\u001b[0;32m    183\u001b[0m     yticks\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49marange(n_classes),\n\u001b[0;32m    184\u001b[0m     xticklabels\u001b[39m=\u001b[39;49mdisplay_labels,\n\u001b[0;32m    185\u001b[0m     yticklabels\u001b[39m=\u001b[39;49mdisplay_labels,\n\u001b[0;32m    186\u001b[0m     ylabel\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mTrue label\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    187\u001b[0m     xlabel\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPredicted label\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    188\u001b[0m )\n\u001b[0;32m    190\u001b[0m ax\u001b[39m.\u001b[39mset_ylim((n_classes \u001b[39m-\u001b[39m \u001b[39m0.5\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.5\u001b[39m))\n\u001b[0;32m    191\u001b[0m plt\u001b[39m.\u001b[39msetp(ax\u001b[39m.\u001b[39mget_xticklabels(), rotation\u001b[39m=\u001b[39mxticks_rotation)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\matplotlib\\artist.py:147\u001b[0m, in \u001b[0;36mArtist.__init_subclass__.<locals>.<lambda>\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mset, \u001b[39m'\u001b[39m\u001b[39m_autogenerated_signature\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    140\u001b[0m     \u001b[39m# Don't overwrite cls.set if the subclass or one of its parents\u001b[39;00m\n\u001b[0;32m    141\u001b[0m     \u001b[39m# has defined a set method set itself.\u001b[39;00m\n\u001b[0;32m    142\u001b[0m     \u001b[39m# If there was no explicit definition, cls.set is inherited from\u001b[39;00m\n\u001b[0;32m    143\u001b[0m     \u001b[39m# the hierarchy of auto-generated set methods, which hold the\u001b[39;00m\n\u001b[0;32m    144\u001b[0m     \u001b[39m# flag _autogenerated_signature.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mset \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m \u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Artist\u001b[39m.\u001b[39;49mset(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    148\u001b[0m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mset\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mset\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    149\u001b[0m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mset\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.set\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\matplotlib\\artist.py:1227\u001b[0m, in \u001b[0;36mArtist.set\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   1223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1224\u001b[0m     \u001b[39m# docstring and signature are auto-generated via\u001b[39;00m\n\u001b[0;32m   1225\u001b[0m     \u001b[39m# Artist._update_set_signature_and_docstring() at the end of the\u001b[39;00m\n\u001b[0;32m   1226\u001b[0m     \u001b[39m# module.\u001b[39;00m\n\u001b[1;32m-> 1227\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_internal_update(cbook\u001b[39m.\u001b[39;49mnormalize_kwargs(kwargs, \u001b[39mself\u001b[39;49m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\matplotlib\\artist.py:1219\u001b[0m, in \u001b[0;36mArtist._internal_update\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m   1212\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_internal_update\u001b[39m(\u001b[39mself\u001b[39m, kwargs):\n\u001b[0;32m   1213\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1214\u001b[0m \u001b[39m    Update artist properties without prenormalizing them, but generating\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[39m    errors as if calling `set`.\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \n\u001b[0;32m   1217\u001b[0m \u001b[39m    The lack of prenormalization is to maintain backcompatibility.\u001b[39;00m\n\u001b[0;32m   1218\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1219\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_props(\n\u001b[0;32m   1220\u001b[0m         kwargs, \u001b[39m\"\u001b[39;49m\u001b[39m{cls.__name__}\u001b[39;49;00m\u001b[39m.set() got an unexpected keyword argument \u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m   1221\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m{prop_name!r}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\matplotlib\\artist.py:1195\u001b[0m, in \u001b[0;36mArtist._update_props\u001b[1;34m(self, props, errfmt)\u001b[0m\n\u001b[0;32m   1192\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mcallable\u001b[39m(func):\n\u001b[0;32m   1193\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[0;32m   1194\u001b[0m                     errfmt\u001b[39m.\u001b[39mformat(\u001b[39mcls\u001b[39m\u001b[39m=\u001b[39m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m), prop_name\u001b[39m=\u001b[39mk))\n\u001b[1;32m-> 1195\u001b[0m             ret\u001b[39m.\u001b[39mappend(func(v))\n\u001b[0;32m   1196\u001b[0m \u001b[39mif\u001b[39;00m ret:\n\u001b[0;32m   1197\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpchanged()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\matplotlib\\axes\\_base.py:73\u001b[0m, in \u001b[0;36m_axis_method_wrapper.__set_name__.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m get_method(\u001b[39mself\u001b[39;49m)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\matplotlib\\_api\\deprecation.py:297\u001b[0m, in \u001b[0;36mrename_parameter.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    292\u001b[0m     warn_deprecated(\n\u001b[0;32m    293\u001b[0m         since, message\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m{\u001b[39;00mold\u001b[39m!r}\u001b[39;00m\u001b[39m parameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m() \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    294\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhas been renamed \u001b[39m\u001b[39m{\u001b[39;00mnew\u001b[39m!r}\u001b[39;00m\u001b[39m since Matplotlib \u001b[39m\u001b[39m{\u001b[39;00msince\u001b[39m}\u001b[39;00m\u001b[39m; support \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    295\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfor the old name will be dropped %(removal)s.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    296\u001b[0m     kwargs[new] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(old)\n\u001b[1;32m--> 297\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\matplotlib\\axis.py:2025\u001b[0m, in \u001b[0;36mAxis.set_ticklabels\u001b[1;34m(self, labels, minor, fontdict, **kwargs)\u001b[0m\n\u001b[0;32m   2021\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(locator, mticker\u001b[39m.\u001b[39mFixedLocator):\n\u001b[0;32m   2022\u001b[0m     \u001b[39m# Passing [] as a list of labels is often used as a way to\u001b[39;00m\n\u001b[0;32m   2023\u001b[0m     \u001b[39m# remove all tick labels, so only error for > 0 labels\u001b[39;00m\n\u001b[0;32m   2024\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(locator\u001b[39m.\u001b[39mlocs) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(labels) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(labels) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m-> 2025\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2026\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe number of FixedLocator locations\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2027\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(locator\u001b[39m.\u001b[39mlocs)\u001b[39m}\u001b[39;00m\u001b[39m), usually from a call to\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2028\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m set_ticks, does not match\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2029\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m the number of labels (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(labels)\u001b[39m}\u001b[39;00m\u001b[39m).\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   2030\u001b[0m     tickd \u001b[39m=\u001b[39m {loc: lab \u001b[39mfor\u001b[39;00m loc, lab \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(locator\u001b[39m.\u001b[39mlocs, labels)}\n\u001b[0;32m   2031\u001b[0m     func \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mpartial(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_with_dict, tickd)\n",
      "\u001b[1;31mValueError\u001b[0m: The number of FixedLocator locations (10), usually from a call to set_ticks, does not match the number of labels (2)."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true, y_pred_bool)\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\n",
    "    'NonViolence' , 'Violence'\n",
    "]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " NonViolence       0.78      0.83      0.81       140\n",
      "    Violence       0.20      0.16      0.18        38\n",
      "\n",
      "    accuracy                           0.69       178\n",
      "   macro avg       0.49      0.49      0.49       178\n",
      "weighted avg       0.66      0.69      0.67       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NV = 0, V = 1\n",
    "print(classification_report(y_true, y_pred_bool, target_names=['NonViolence', 'Violence']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
