{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install opencv-python\n",
    "%pip install tqdm\n",
    "%pip install tensorflow\n",
    "%pip install imageio\n",
    "%pip install tensorflow_docs\n",
    "%pip install scikit-learn\n",
    "%pip install matplotlib\n",
    "%pip install keras-tuner\n",
    "%pip install pandas\n",
    "%pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2alex\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\2alex\\AppData\\Local\\Temp\\ipykernel_48212\\3076716110.py:19: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import RandomSearch\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pathlib\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import imageio\n",
    "from IPython import display\n",
    "from urllib import request\n",
    "from tensorflow_docs.vis import embed\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "import tensorflow_addons as tfa\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from keras_tuner import Objective\n",
    "from keras.optimizers import SGD, Adam, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_paths = {}\n",
    "subset_paths['train'] = Path(r'C:\\Users\\2alex\\OneDrive\\Documents\\GitHub\\FightClub\\Data\\train')\n",
    "subset_paths['test'] = Path(r'C:\\Users\\2alex\\OneDrive\\Documents\\GitHub\\FightClub\\Data\\test')\n",
    "subset_paths['val'] = Path(r'C:\\Users\\2alex\\OneDrive\\Documents\\GitHub\\FightClub\\Data\\val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_frames(frame, output_size):\n",
    "    \"\"\"\n",
    "      Pad and resize an image from a video.\n",
    "\n",
    "      Args:\n",
    "        frame: Image that needs to resized and padded.\n",
    "        output_size: Pixel size of the output frame image.\n",
    "\n",
    "      Return:\n",
    "        Formatted frame with padding of specified output size.\n",
    "    \"\"\"\n",
    "    frame = tf.image.convert_image_dtype(frame, tf.float32)\n",
    "    frame = tf.image.resize_with_pad(frame, *output_size)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frames_from_video_file(video_path, n_frames, output_size=(224, 224), frame_step=15):\n",
    "    \"\"\"\n",
    "      Creates frames from each video file present for each category.\n",
    "\n",
    "      Args:\n",
    "        video_path: File path to the video.\n",
    "        n_frames: Number of frames to be created per video file.\n",
    "        output_size: Pixel size of the output frame image.\n",
    "\n",
    "      Return:\n",
    "        An NumPy array of frames in the shape of (n_frames, height, width, channels).\n",
    "    \"\"\"\n",
    "    # Read each video frame by frame\n",
    "    result = []\n",
    "    src = cv2.VideoCapture(str(video_path))\n",
    "\n",
    "    video_length = src.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "    need_length = 1 + (n_frames - 1) * frame_step\n",
    "\n",
    "    if need_length > video_length:\n",
    "        start = 0\n",
    "    else:\n",
    "        max_start = video_length - need_length\n",
    "        start = random.randint(0, max_start + 1)\n",
    "\n",
    "    src.set(cv2.CAP_PROP_POS_FRAMES, start)\n",
    "    # ret is a boolean indicating whether read was successful, frame is the image itself\n",
    "    ret, frame = src.read()\n",
    "    result.append(format_frames(frame, output_size))\n",
    "\n",
    "    for _ in range(n_frames - 1):\n",
    "        for _ in range(frame_step):\n",
    "            ret, frame = src.read()\n",
    "        if ret:\n",
    "            frame = format_frames(frame, output_size)\n",
    "            result.append(frame)\n",
    "        else:\n",
    "            result.append(np.zeros_like(result[0]))\n",
    "    src.release()\n",
    "    result = np.array(result)[..., [2, 1, 0]]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrameGenerator:\n",
    "    def __init__(self, path, n_frames, training=False):\n",
    "        \"\"\" Returns a set of frames with their associated label.\n",
    "\n",
    "          Args:\n",
    "            path: Video file paths.\n",
    "            n_frames: Number of frames.\n",
    "            training: Boolean to determine if training dataset is being created.\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "        self.n_frames = n_frames\n",
    "        self.training = training\n",
    "        self.class_names = sorted(\n",
    "            set(p.name for p in self.path.iterdir() if p.is_dir()))\n",
    "        self.class_ids_for_name = dict((name, idx)\n",
    "                                       for idx, name in enumerate(self.class_names))\n",
    "\n",
    "    def get_files_and_class_names(self):\n",
    "        video_paths = list(self.path.glob('*/*.mp4'))\n",
    "        classes = [p.parent.name for p in video_paths]\n",
    "        return video_paths, classes\n",
    "\n",
    "    def __call__(self):\n",
    "        video_paths, classes = self.get_files_and_class_names()\n",
    "        pairs = list(zip(video_paths, classes))\n",
    "\n",
    "        if self.training:\n",
    "            random.shuffle(pairs)\n",
    "\n",
    "        for path, name in pairs:\n",
    "            video_frames = frames_from_video_file(path, self.n_frames)\n",
    "            label = self.class_ids_for_name[name]\n",
    "            # Encode labels\n",
    "            yield video_frames, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_signature = (tf.TensorSpec(shape=(None, None, None, 3), dtype=tf.float32),\n",
    "                    tf.TensorSpec(shape=(), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training set\n",
    "train_ds = tf.data.Dataset.from_generator(FrameGenerator(\n",
    "    subset_paths['train'], 6, training=True),                                        output_signature=output_signature)\n",
    "# Create the validation set\n",
    "val_ds = tf.data.Dataset.from_generator(FrameGenerator(subset_paths['val'], 6),\n",
    "                                        output_signature=output_signature)\n",
    "# create the test set\n",
    "test_ds = tf.data.Dataset.from_generator(FrameGenerator(subset_paths['test'], 6),\n",
    "                                         output_signature=output_signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "train_ds = train_ds.batch(2)\n",
    "val_ds = val_ds.batch(2)\n",
    "test_ds = val_ds.batch(2)\n",
    "\n",
    "train_frames, train_labels = next(iter(train_ds))\n",
    "val_frames, val_labels = next(iter(val_ds))\n",
    "test_frames, test_labels = next(iter(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = tf.keras.applications.EfficientNetB0(include_top=False)\n",
    "net.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Rescaling(scale=255))\n",
    "    model.add(tf.keras.layers.TimeDistributed(net))\n",
    "    model.add(tf.keras.layers.Dense(units=hp.Int(\n",
    "        'units', min_value=32, max_value=512, step=32), activation='relu'))\n",
    "    model.add(tf.keras.layers.GlobalAveragePooling3D())\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    custom_optimizer = keras.optimizers.Adam(\n",
    "        learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4]),\n",
    "        beta_1=hp.Choice('beta_1', values=[0.9, 0.99, 0.999]),\n",
    "        beta_2=hp.Choice('beta_2', values=[0.999, 0.9999]),\n",
    "        epsilon=hp.Float('epsilon', min_value=1e-10, max_value=1e-7)\n",
    "    )\n",
    "\n",
    "    # Define metrics\n",
    "    #metrics = [tf.keras.metrics.AUC(), tf.keras.metrics.Recall(), tf.keras.metrics.Precision(), tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.TruePositives(), tf.keras.metrics.TrueNegatives(), tf.keras.metrics.FalseNegatives(), tf.keras.metrics.FalsePositives()]\n",
    "\n",
    "\n",
    "    # Running with SGD optimizer\n",
    "    model.compile(optimizer=custom_optimizer,\n",
    "                  loss=keras.losses.binary_crossentropy, metrics='accuracy')\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from adam_accuracy_directory/logs\\untitled_project\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "# Initialize the tuner\n",
    "tuner = RandomSearch(\n",
    "    model_builder,\n",
    "    # understand 'objective' should be converted to binary\n",
    "    objective=Objective(tfa.metrics.F1Score(name='val_loss', num_classes=1, average='macro',threshold=0.5), direction=max), # 'val_accuracy'\n",
    "    max_trials=10,  # Adjust the number of trials as needed\n",
    "    directory='adam_accuracy_directory/logs'  # For accuracy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks, such as early stopping, if necessary\n",
    "\n",
    "combined = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)]\n",
    "\n",
    "# Start the tuning process\n",
    "tuner.search(train_ds, epochs=10, validation_data=(\n",
    "    val_ds), callbacks=combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in adam_accuracy_directory/logs\\untitled_project\n",
      "Showing 10 best trials\n",
      "Objective(name=\"F1Score(name=val_loss,dtype=float32,num_classes=1,average=macro,threshold=0.5)\", direction=\"<built-in function max>\")\n",
      "\n",
      "Trial 01 summary\n",
      "Hyperparameters:\n",
      "units: 384\n",
      "learning_rate: 0.001\n",
      "beta_1: 0.999\n",
      "beta_2: 0.9999\n",
      "epsilon: 5.955380768793277e-08\n",
      "Score: 0.800000011920929\n",
      "\n",
      "Trial 04 summary\n",
      "Hyperparameters:\n",
      "units: 256\n",
      "learning_rate: 0.01\n",
      "beta_1: 0.99\n",
      "beta_2: 0.9999\n",
      "epsilon: 1.8779680855635415e-09\n",
      "Score: 0.800000011920929\n",
      "\n",
      "Trial 06 summary\n",
      "Hyperparameters:\n",
      "units: 64\n",
      "learning_rate: 0.0001\n",
      "beta_1: 0.99\n",
      "beta_2: 0.999\n",
      "epsilon: 5.294146043098329e-08\n",
      "Score: 0.800000011920929\n",
      "\n",
      "Trial 09 summary\n",
      "Hyperparameters:\n",
      "units: 256\n",
      "learning_rate: 0.0001\n",
      "beta_1: 0.9\n",
      "beta_2: 0.999\n",
      "epsilon: 1.376496785140196e-08\n",
      "Score: 0.8166666626930237\n",
      "\n",
      "Trial 03 summary\n",
      "Hyperparameters:\n",
      "units: 480\n",
      "learning_rate: 0.0001\n",
      "beta_1: 0.99\n",
      "beta_2: 0.999\n",
      "epsilon: 1.0407582549292059e-08\n",
      "Score: 0.8166666626930237\n",
      "\n",
      "Trial 02 summary\n",
      "Hyperparameters:\n",
      "units: 96\n",
      "learning_rate: 0.0001\n",
      "beta_1: 0.9\n",
      "beta_2: 0.9999\n",
      "epsilon: 6.349624073031776e-08\n",
      "Score: 0.8166666626930237\n",
      "\n",
      "Trial 00 summary\n",
      "Hyperparameters:\n",
      "units: 352\n",
      "learning_rate: 0.001\n",
      "beta_1: 0.9\n",
      "beta_2: 0.999\n",
      "epsilon: 1.447326948250435e-08\n",
      "Score: 0.8333333134651184\n",
      "\n",
      "Trial 05 summary\n",
      "Hyperparameters:\n",
      "units: 288\n",
      "learning_rate: 0.001\n",
      "beta_1: 0.9\n",
      "beta_2: 0.999\n",
      "epsilon: 6.297480105726857e-08\n",
      "Score: 0.8500000238418579\n",
      "\n",
      "Trial 07 summary\n",
      "Hyperparameters:\n",
      "units: 224\n",
      "learning_rate: 0.001\n",
      "beta_1: 0.9\n",
      "beta_2: 0.9999\n",
      "epsilon: 4.06210026694577e-08\n",
      "Score: 0.8500000238418579\n",
      "\n",
      "Trial 08 summary\n",
      "Hyperparameters:\n",
      "units: 416\n",
      "learning_rate: 0.001\n",
      "beta_1: 0.9\n",
      "beta_2: 0.9999\n",
      "epsilon: 8.740751094720674e-08\n",
      "Score: 0.8500000238418579\n"
     ]
    }
   ],
   "source": [
    "# Each trial tests different parameters over 10 epochs\n",
    "tuner.results_summary()\n",
    "\n",
    "# SGD\n",
    "# Trial 06 summary\n",
    "# Hyperparameters:\n",
    "# units: 128\n",
    "# learning_rate: 0.01\n",
    "# beta_1: 0.9\n",
    "# beta_2: 0.999\n",
    "# epsilon: 6.329346769904573e-09\n",
    "# Score: 0.8500000238418579\n",
    "\n",
    "# Adam\n",
    "# Trial 05 summary\n",
    "# Hyperparameters:\n",
    "# units: 288\n",
    "# learning_rate: 0.001\n",
    "# beta_1: 0.9\n",
    "# beta_2: 0.999\n",
    "# epsilon: 6.297480105726857e-08\n",
    "# Score: 0.8500000238418579\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 5\n",
      "units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n",
      "beta_1 (Choice)\n",
      "{'default': 0.9, 'conditions': [], 'values': [0.9, 0.99, 0.999], 'ordered': True}\n",
      "beta_2 (Choice)\n",
      "{'default': 0.999, 'conditions': [], 'values': [0.999, 0.9999], 'ordered': True}\n",
      "epsilon (Float)\n",
      "{'default': 1e-10, 'conditions': [], 'min_value': 1e-10, 'max_value': 1e-07, 'step': None, 'sampling': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Tensorboard\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      "<keras_tuner.src.engine.hyperparameters.hyperparameters.HyperParameters object at 0x0000019C99F8CB50>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute '_nested_inputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\2alex\\OneDrive\\Documents\\GitHub\\FightClub\\efficientnet\\tune_efficientnet.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/2alex/OneDrive/Documents/GitHub/FightClub/efficientnet/tune_efficientnet.ipynb#X20sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m\"\"\"best_model.compile(\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/2alex/OneDrive/Documents/GitHub/FightClub/efficientnet/tune_efficientnet.ipynb#X20sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m    optimizer=best_hps['optimizer'], loss='binary_crossentropy', metrics=['recall'])\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/2alex/OneDrive/Documents/GitHub/FightClub/efficientnet/tune_efficientnet.ipynb#X20sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m layer_names \u001b[39m=\u001b[39m [layer\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m best_model\u001b[39m.\u001b[39mlayers]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/2alex/OneDrive/Documents/GitHub/FightClub/efficientnet/tune_efficientnet.ipynb#X20sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m intermediate_layer_model \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mModel(inputs\u001b[39m=\u001b[39mbest_model\u001b[39m.\u001b[39;49minput,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/2alex/OneDrive/Documents/GitHub/FightClub/efficientnet/tune_efficientnet.ipynb#X20sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m                                          outputs\u001b[39m=\u001b[39m[best_model\u001b[39m.\u001b[39mget_layer(name)\u001b[39m.\u001b[39moutput \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m layer_names])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/2alex/OneDrive/Documents/GitHub/FightClub/efficientnet/tune_efficientnet.ipynb#X20sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m intermediate_outputs \u001b[39m=\u001b[39m intermediate_layer_model\u001b[39m.\u001b[39mpredict(test_ds)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/2alex/OneDrive/Documents/GitHub/FightClub/efficientnet/tune_efficientnet.ipynb#X20sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Plot intermediate layer outputs\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\functional.py:322\u001b[0m, in \u001b[0;36mFunctional.input\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m    309\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minput\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    310\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Retrieves the input tensor(s) of a layer.\u001b[39;00m\n\u001b[0;32m    311\u001b[0m \n\u001b[0;32m    312\u001b[0m \u001b[39m    Only applicable if the layer has exactly one input,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[39m      AttributeError: If no inbound nodes are found.\u001b[39;00m\n\u001b[0;32m    321\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 322\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_nested_inputs\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute '_nested_inputs'"
     ]
    }
   ],
   "source": [
    "# Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(best_hps)\n",
    "\n",
    "# Build and compile the final model with the best hyperparameters\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "\"\"\"best_model.compile(\n",
    "    optimizer=best_hps['optimizer'], loss='binary_crossentropy', metrics=[keras.metrics.Recall()])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the final model\n",
    "history = best_model.fit(x=train_ds, epochs=10, validation_data=(val_ds))\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "\n",
    "print('Best Epoch: %d' % (best_epoch,))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
